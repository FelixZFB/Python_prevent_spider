
# 0 前言
## 0.1 反爬虫按设计目的分类
- 限制手段
    - 请求限制、拒绝响应、客户端身份验证、文本混淆、动态渲染等手段
- 主动型反爬虫
    - 开发者有意识的使用技术手段区分正常用户和爬虫，并限制爬虫对网站的访问行为。
    - 比如验证请求头信息、限制访问的频率、使用验证码等
- 被动型反爬虫
    - 为了提升用户体验和节省资源，使用了一些技术间接提高了爬虫访问难度的行为
    - 比如数据分段加载(js动态加载数据)、点击切换标签页(切换时候请求加载数据)、鼠标悬停预览数据(鼠标悬停动作加载数据)
    

## 0.2 反爬虫按特点分类
- 信息校验型反爬虫：网络请求阶段，预防为主要目的，尽可能的拒绝爬虫的请求
- 动态渲染型反爬虫：文本获取和数据提取阶段，保护数据为主要目的，尽可能避免爬虫获取重要数据
- 文本混淆反爬虫：文本获取和数据提取阶段，保护数据为主要目的，尽可能避免爬虫获取重要数据
- 特征识别反爬虫：预防为主要目的，直指爬虫出现的源头
- APP反爬虫：
- 验证码反爬虫：

## 反爬虫



# 1 环境配置
## 1.1 Docker容器
- Docker容器可以和虚拟机一样实现资源和系统环境的隔离
- Docker是一个用Go语言编写的开源的应用容器引擎
    - 特点：轻量、便捷、低开销
    - 用途：允许开发者将应用和对应的运行环境包装到一个可移植的容器中，并
    发布到任何装有Docker的机器上
- Docker与VM虚拟机的区别：
    - VM(VMware)在宿主机器、宿主机器操作系统的基础上创建虚拟层、虚拟化的操作系统、虚拟化的仓库，然后再安装应用；
    - Container(Docker容器)，在宿主机器、宿主机器操作系统上创建Docker引擎，在引擎的基础上再安装应用。
    - Docker在宿主机器的操作系统上创建Docker引擎，直接在宿主主机的操作系统上调用硬件资源，而不是虚拟化操作系统和硬件资源，所以操作速度快。
- Docker安装参考博文：
[Ubuntu18.04 安装Docker（安装常见报错及Docker常用命令）](https://blog.csdn.net/u011318077/article/details/104733149)

## 1.2 yum命令安装
- yum（ Yellow dog Updater, Modified）是一个在Fedora和RedHat以及SUSE中的Shell前端软件包管理器。
- yum 语法,使用和pip命令类似
    - yum [options] [command] [package ...]
    - options：可选，选项包括-h（帮助），-y（当安装过程提示选择全部为"yes"），-q（不显示安装的过程）等等。
    - command：要进行的操作。
    - package操作的对象。
    - sudo yum install pam-devel   安装包
    - sudo yum remove pam-devel    卸载包
- ubuntu18.04安装yum命令：sudo apt-get install yum

## 1.3 nginx服务安装
- Nginx是一款轻量级的Web 服务器/反向代理服务器及电子邮件（IMAP/POP3）代理服务器，在BSD-like 协议下发行。
- 特点是占有内存少，并发能力强，事实上nginx的并发能力在同类型的网页服务器中表现较好

- nginx安装：
    - sudo apt-get install nginx      安装命令
    - sudo /etc/init.d/nginx status   查看nginx运行状态
    - sudo /etc/init.d/nginx start    启动nginx
    - sudo /etc/init.d/nginx restart  重启nginx
    - sudo nginx -s reload            不重启下重载配置文件，一般修改配置文件后执行改命令
    - sudo find / -name nginx.conf    查看当前使用的配置文件

- 安装完成后：访问 http://localhost  显示Welcome to nginx!

- nginx文件说明：
    - 程序文件在 /usr/sbin/nginx
    - 日志文件 /var/log/nginx
    - 一些相关配置文件在 /etc/nginx/*下
    - 存放静态文件 /usr/share/nginx 

- [Ubuntu 16.04安装Nginx以及相关配置](https://blog.csdn.net/javahighness/article/details/80500437?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task)


# 2 信息验证型反爬虫
## 2.1 User-Agent反爬虫
- User-Agent是用户身份识别的重要信息，User-Agent中包含用户浏览器、浏览器引擎、操作系统等信息
- python的requests库请求时候，服务器读取到的User-Agent信息就是 python-requests/2.21.0
- User-Agent反爬虫：
    - nginx中加入User-Agent检测，将python，Java，PHP等一些关键词都加入到黑名单中
    - 检测时候，发现含有这些关键词，就认定为是爬虫程序
- 除了User-Agent头部信息，常用的还有Host,Referer头部信息
    - 1. Host 描述请求将被发送的目的地，只含域名和端口号；
    - 2. Origin 请求是从哪里发起的，包括域名和端口号，这个参数一般存在于CORS跨域请求中，
        可以看到response有对应的header: Access-Control-Allow-Origin
    - 3. Referer 告知服务器请求的原始资源的URI,其用于所有类型的请求，包括：协议+域名+查询参数


## 2.2 Cookies反爬虫
- 服务器端，一般是Nginx中加入检测请求头信息中是否有http_cookie信息,然后返回不同的结果。
- 浏览器正常请求网页，服务器返回的cookie会自动保存在本地，下次访问时候会自动携带
- 没有携带cookie访问，返回结果都是重定向，一般都是重定向30x,一般都是定位到首页或者登陆页面

## 2.3 签名验证反爬虫
- JavaScript异步动态请求类型一般都是xhr(ajax封装对象)，可以在请求里面查找类型为xhr的请求，请求源一般都是js文件
- 请求正文内容里面有特征值是32位（一般是MD5加密后字段），一般可以大胆猜测就是签名验证反爬虫，
- 加密内容都是使用JavaScript里面的函数生成的，通过进js文件搜索关键字，就可以找到加密字段的生成方式

- 案例1：
- 访问一下网址，然后点击查看详情
    - http://www.porters.vip/verify/sign/
    - 上述网址，点击查看详情，查看network
    - 下面网址就是动态加密生成的，直接复制去请求是无效的，网址有多个参数还有时间戳，直接浏览器再次去请求就是无效的
    - http://www.porters.vip/verify/sign/fet?actions=31288&tim=1583827827&randstr=JUBMB&sign=1f46e27e48caacc155fbf9afde6bbbc0
    - 动态加密请求，就是需要破解动态网址是如何生成的
    - 点击查看详情，network里面有一个fet.....开头的网址请求，类型是xhr(ajax封装的对象)

- 查看网址，点击查看详情位置，参考图片005，发现onclick绑定一个fetch()函数
    - 表明点击后执行该函数，函数都是放在js代码里面，head里面发现引入了两个自定义的js文件
    - Chrome检查，查看，右键在js文件上，open in new tab
    - 查看fetch()函数具体内容，函数访问一个动态生成的网址，网页内容插入替换原始网页id="content"标签的内容
    - 然后我们在python中实现该真实网址的生成方式

- 案例2：
- 有道翻译加密分析：
    - 打开有道翻译，输入中国，network里面出现一个xhr类型的post请求，请求源Initiator是一个js文件
    - post请求，Request URL: http://fanyi.youdao.com/translate_o?smartresult=dict&smartresult=rule
    - 请求体的formdata里面有很多参数，i就是要翻译的字符串
    - 加密的参数进请求源js文件里面搜索，可以找到参数的生成方式
    - 具体参考006图片
    - 实际有道翻译加密只需要保留formdata中的i和doctype就可以获取翻译后的json数据，直接忽略加密内容
    - 参考006案例
    
    
## 2.4 js动态请求补充：
- 网页源码中（Name，Status，Type，Initiator，Size，Time，Waterfall）的含义
    - 第一列 Name ：请求的名称，一般会将URL 最后一部分内容当作名称
    - 第二列 Status ：响应的状态码，显示为 200 代表响应是正常的 通过状态码，我们可以判断发送了请求之后是否得到了正常的响应 。
    - 第三列 Type： 请求的文档类型 。这里为 document ，代表我们这次请求的是 HTML 文档， 内容就是一些 HTML 代码。
    - 第四列 Initiator： 请求源。 用来标记请求是由哪个对象或进程发起的
    - 第五列 Size : 从服务器下载的文件和请求的资源大小。 如果是从缓存中取得的资源，则该列 会显示from cache。
    - 第六列 Time : 发起请求到获取响应所用的总时间
    - 第七列 Waterfall：网络请求的可视化瀑布流

- 动态ajax请求一般是xhr类型
    - xhr：XMLHttpRequest在后台与服务器交换数据，这意味着可以在不加载整个网页的情况下，对网页某部分的内容进行更新。
    是Ajax的一种用法，而Ajax并不是一门语言，只是一种不需要加载整个网页，只是更新局部内容的技术。

    - 案例：
    - 比较常见的就是网页内容繁多，我们仅仅看评论时，无需整个页面都加载，
    - 那么就可以采用这种方式来实现，只需要在翻页时，局部加载评论的内容即可。

- js(ajax)动态请求
    - 1、在使用Chrome或者firebug抓取类似网页的内容时，只需要找到xhr类型的url地址，Initiator请求源一般是一个js文件
    - 2、在浏览器地址栏中打开即可看到对应的内容。
    - 3、一般情况为json格式，
    - 4、再利用python等语言抓取json中的需要的内容即可
    

# 3 动态渲染反爬虫  
## 3.1 Selenium工具
- 工具1：Selenium + Chrome + 驱动器 三件套抓取动态渲染网页
    - 缺点：执行效率低，占用系统资源大，不能异步请求

## 3.2 Puppeteer工具
- 工具2：Puppeteer(python中的库叫pyppeteer)
- 安装：
    - 安装命令：
        pip install pyppeteer
        python -m pip install pyppeteer
    - 从GIT安装最新版本：python -m pip install -U git+https://github.com/miyakogi/pyppeteer.git@dev
    
    - 推荐安装方式：
        - 第一步：需要先安装支持库 pip install tdqm
        - 第二步：pip install pyppeteer
        - 第三步：含有pyppeteer的代码运行时候，会自动下载chromium解压安装（Chrome的实验版）
- 参考案例008

## 3.3 Splash异步渲染服务
- Splash是一个异步的JavaScript的渲染服务，它带有HTTP API的轻量级Web服务器。
- 可视化界面地址：http://www.porters.vip:8050/      
- 上面地址输入网址，然后render me就可以获取网页的截图、资源加载数据、HTML原始文本
- 脚本里面也可以自己编写，但是使用的是Lua语言
- 参考009图片

- Splash服务也可以和Python语言结合使用
- 参考案例009

- 上面三种渲染工具对比：
    - Selenium套件通过驱动浏览器执行操作，本质上是模拟浏览器操作
    - Puppeteer实际上通过API控制Chromium或者Chrome浏览器
    - Splash基于开源的浏览器引擎WebKit
    

# 4 文本混淆反爬虫
## 4.1 图片伪装为文字反爬虫
- 有些文字内容实际是图片伪装的
- 提取图片的内容(图片请求响应结果res.content就是图片的字节数据，可以直接write为图片对象，也可以打开为图片对象，看案例)
- 图片对象使用光学字符识别技术(pytesseract库)从图片中提取文字
- PyTesseract缺点：只能识别出一些清晰工整的图像中的文字，扭曲的文字或者有其它颜色图片干扰信息时候识别不准确
- 参考案例001(02文件夹中)

## 4.2 CSS偏移反爬虫
- 一般用于数字显示，源码中有很多数字，用于混淆
- 网页中显示的出来的内容的位置是固定的，源码中的数字进行偏移覆盖才是最终显示出来的数字
- 去哪儿网的航班票价就是进行CSS偏移处理过的
- 前面有数字120  下面有数字002
- 002通过不同的左右偏移位置覆盖在120的数字上才是最终显示结果
- 参考图片002

## 4.3 SVG图形映射反爬虫
- SVG是一种二维矢量图形格式，放大缩小清晰度保持不变
- SVG映射反爬虫：前端或者后端里面将文字或者数字映射为对应SVG图形文件
网页源码中显示的是SVG图形文件，并没有实际的文字或者数字内容
- 最常用于团购网站商家电话的替换
- 映射替换有两种方式：
    - 方式1：一个SVG图片代表一个数字或者文字。要显示内容的地方使用SVG图片替代，一般是设置class样式，然后设置背景图片，用SVG图片插到盒子中
    - 方式2：将所有的数字或者文字都放在一张SVG图片上，然后设置为背景图片，然后通过偏移图片的位置显示内容
    - 方式3：将所有的数字或者文字都放在一张SVG图片上，然后设置为背景图片，图片位置不同，SVG图片里面的的数字是可以通过改变xy轴坐标显示的位置的
    - 具体参考图书的P181页，关键是找到映射的规律
    
## 4.4 自定义网页字体(常用woff格式字体)反爬虫
- 自定义的字体格式：woff ttf eot otf
- 文中的数字使用自定义字体样式进行替代，查看元素数字都是显示的方框或者其它特殊符号
- 查看元素里面可以数字都有一个class样式，查看该class样式具体内容，只用一个font-family，对应的值就是自定义的字体样式
- 查看源码，数字是一些特殊编码，特殊编码就是字体文件里面定义的数字对应的编码
- woff等字体文件请求的网址，可以下载字体文件到本地，然后使用
- 百度在线字体编辑打开查看：http://fontstore.baidu.com/static/editor/index.html
- 参考003图片

- WOFF字体文件研究
    - WOFF(Web Open Font Format, web开放字体样式)是一种网页采用的字体格式标准
    - 本质上WOFF是基于SFNT字体，具有TrueType字体的结构，TrueType字体由网格上一系列的点进行描述，点是字体的最小单位
    - WOFF文件等字体文件可以使用python中的第三方fonttools转换为XML文件，便于观察里面的具体数据
    - pip install fonttools
    - 参考案例004
    - 打开XML文件，下面内容就是描述数字6的字形文件
        - TTGlyph里面有字形的名称、x和y轴坐标数据（可理解为字形的宽和高）
        - contour里面只字形的轮廓信息，即多个点的坐标位置，就是这些点连接在一起构成一个字形
    - 注意：相同的字形的宽高或者轮廓点可能会不一样，但是它们描述的会是一个字形
        因此，只有起止坐标和点坐标数据完全一样的字形，我们才能肯定它们是相同的字符
```
<TTGlyph name="uniE339" xMin="0" yMin="-12" xMax="510" yMax="719">
      <contour>
        <pt x="410" y="534" on="1"/>
        <pt x="398" y="586" on="0"/>
        <pt x="377" y="609" on="1"/>
        <pt x="341" y="646" on="0"/>
        <pt x="289" y="646" on="1"/>
        <pt x="247" y="646" on="0"/>
        <pt x="215" y="623" on="1"/>
        <pt x="173" y="592" on="0"/>
        <pt x="150" y="535" on="1"/>
        <pt x="138" y="506" on="0"/>
        <pt x="125" y="423" on="0"/>
        <pt x="125" y="369" on="1"/>
        <pt x="157" y="418" on="0"/>
        <pt x="248" y="464" on="0"/>
        <pt x="299" y="464" on="1"/>
        <pt x="386" y="464" on="0"/>
        <pt x="510" y="334" on="0"/>
        <pt x="510" y="232" on="1"/>
        <pt x="510" y="165" on="0"/>
        <pt x="452" y="49" on="0"/>
        <pt x="352" y="-12" on="0"/>
        <pt x="286" y="-12" on="1"/>
        <pt x="176" y="-12" on="0"/>
        <pt x="38" y="147" on="0"/>
        <pt x="38" y="335" on="1"/>
        <pt x="38" y="543" on="0"/>
        <pt x="114" y="637" on="1"/>
        <pt x="181" y="719" on="0"/>
        <pt x="294" y="719" on="1"/>
        <pt x="379" y="719" on="0"/>
        <pt x="433" y="671" on="1"/>
        <pt x="486" y="625" on="0"/>
        <pt x="498" y="541" on="1"/>
      </contour>
      <contour>
        <pt x="139" y="232" on="1"/>
        <pt x="139" y="188" on="0"/>
        <pt x="178" y="103" on="0"/>
        <pt x="247" y="60" on="0"/>
        <pt x="285" y="60" on="1"/>
        <pt x="339" y="60" on="0"/>
        <pt x="420" y="150" on="0"/>
        <pt x="420" y="227" on="1"/>
        <pt x="420" y="300" on="0"/>
        <pt x="341" y="387" on="0"/>
        <pt x="223" y="387" on="0"/>
        <pt x="139" y="301" on="0"/>
      </contour>
      <instructions/>
    </TTGlyph>
```

- 可以利用fonttools打开网页的字体文件进行分析
    - 找出每个字符映射到网页源码中的代码，实现WOFF字形文件的映射文件
    - 但是如果开发者经常更换字体文件或者使用多套woff字体文件随机切换(只需要引用路径随机更换即可，网页源码使用了字体样式，字符代码就会自动更换)
    - 会使爬取难度越来越大

## 4.5 文本混淆爬虫通用解决方法
- 光学字符识别OCR可以是识别图形中的文字，但是WOFF字体文件和SVG图形中文字太多或者干扰因素多的时候就无法识别
- 解决方法：
    - 使用Python连接Splash渲染工具，进行网页所需部分的截图
    - 拿到截图后保存到本地
    - 使用PyTesseract库识别指定的图片
    - 该方法缺点：PyTesseract是一个开源库，识别率较低
    - 解决方法: 使用第三方文字识别API
        - 腾讯云OCR识别（识别率高，但是要收费）
        - https://cloud.tencent.com/act/event/ocrdemo
    - 参考案例005及书中P202
      
      
# 5 特征识别爬虫
- HTML文档对象 DOM
    - HTML文档对象DOM(Document Object Model)  
    - HTML DOM对象是对HTML文档所有元素进行访问的入口，这个入口就是文档对象模型，简称DOM
    - DOM是W3C组织推荐的处理可扩展标志语言的标准编程接口
    - DOM以面向对象的方式描述文档模型，定义了表示和修改文档所需要的对象的名称、对象的行为、对象的属性以及和对象之间的关系
    - 在网页中，组织页面或者文档对象被放在一个树形的结构中，其中用来表示对象的标准模型就是DOM
    - HTML文档树形结构最顶层的对象就是document
    - DOM也可以理解为一个容器，EChats中绘图前都需要在网页中准备一个DOM容器对象

- 浏览器器对象 BOM
    - 浏览器对象模型BOM(Browser Object Model)
    - BOM对象是用来获取和操作浏览器的属性，主要对象有
        - window: 浏览器窗口对象，所有的JavaScript全局对象、函数和变量均自动成为该对象的成员
        - window.navigator：访问者浏览器的相关信息
        - window.location: 窗口当前显示的文档的web地址
        - window.screen: 访问者浏览器的屏幕信息
        - window.onload：HTML文档整体加载后，再执行window.onload里面的代码

- 详细DOM和BOM对象属性和方法查看图书P66-P69

## 5.1 Webdriver识别反爬虫
- webdriver特征是可以修改的，不可靠
- 参考案例006

## 5.2 浏览器特征
- navigator.userAgent  浏览器器属性
- navigator.platform   用户计算机信息
- 参考截图007_浏览器特征
- 上面的浏览器特征也是和navigator.webdriver一样可以认为进行修改的，一样不可靠

## 5.3 爬虫特征
- IP地址访问频率限制：使用IP池，分布式爬虫(多台机器轮流访问)
- 用户凭证（cookie或者token）和浏览器指纹限制：
    - web框架自带访问频率限制：登陆用户每天访问1000次，未登录每天100次
    - web框架自带限速模块Throttling
- 用户凭证反爬虫：申请大量用户，访问时候随机携带cookie或token值，类似IP代理池

- 登录用户可靠凭证：cookie或token
- 未登录用户可靠凭证：
    - Canvas生成的指纹、WebGL生成的指纹、Navigator对象的属性值、客户端其它属性值，综合生成的特征值
    - Fingerprint.js库可以生成一个重复率极低的特征指纹

## 5.4 隐藏连接反爬虫
- 隐藏连接反爬虫一般使用在大量列表中，将个别列表成员的css属性添加一个隐藏属性，display：none
- 正常页面该盒子已被隐藏，用户浏览器访问不到，但是爬虫循环访问时候可以访问到
- 后端设置访问该链接就被视为爬虫，然后将IP加入黑名单，实现了反爬
- 隐藏式连接，利用的是爬虫工程师的粗细大意，仔细检查就可以避免访问隐藏式连接


# 6 App 反爬虫
## 6.1 App抓包
- 抓包是利用第三方作为代理，实现监听网络传输与收发数据的行为
### 6.1.1 HTTP 抓包
- 抓包软件Charles、Fiddler、Wireshark
- 注意抓包软件和要抓包的电脑或者手机要处于同一个网络

## 6.2 APK反编译


## 6.3 代码混淆


# 7 验证码
## 7.1 字符验证码
- 特征：图片上面绘制的数字或者字母，底色有混淆图案
- 思路：
    - selenium等渲染工具保存验证码截图
    - pytesseract等OCR识别工具识别
- PyTesseract识别工具
    - 缺点：pytesseract识别率较低，识别不出来就没有任何结果
    - 即使进行二值化和灰度处理，很多还是无法识别
    - 使用腾讯云的ocr识别，还是有些无法识别
- 复杂验证码识别：
    - 使用卷积神经网络预测验证码：常用框架TensorFlow、PyTorch、Caffe
    - 先学习大量验证码图片，然后最终识别率可以达到99%以上
- 安考案例001

## 7.2 计算型验证码
- 特征：计算两个数字的加减乘计算得到结果
- 思路
    - selenium或者其它自动化渲染工具对指定元素进行截图
    - pytesseract识别图片为字符串
    - re正则查找数字和计算符号，然后计算结果
    - 然后向输入框输入结果最后点击登录
- 参考案例002

- selenium下对指定元素进行截图
```python
from selenium import webdriver
driver = webdriver.Chrome()
driver.maximize_window() # 最大化窗口
driver.get("https://www.autohome.com.cn")
 
driver.save_screenshot('capture.png')    #全屏截图

ele = driver.find_element_by_id('s4612')
ele.screenshot('ele.png')    #元素截图
```

## 7.3 滑动验证码
- 特征：滑块的滑动路线和滑动距离都是固定的
- 思路
    - selenium打开浏览器
    - 定位滑块和滑轨元素
    - 获取元素css属性的width值，计算滑动距离
    - 使用ActionChains模块滑动滑块到目标位置
    - 验证完成
- 参考案例003

## 7.4 滑动拼图验证码
- 特征：一个方块滑动到一个缺口完成拼图，一般都是水平向右滑动，
    - 但是滑块起始位置和终点位置是随机出现的
    - 滑动轨道和滑动距离都是随机的
- 滑动拼图实现1：
    - 按下滑块，缺口图形和缺口模块的style样式添加left属性值
    - 通过left属性值计算出滑动距离
- 滑动拼图实现2：
    - 缺口不是通过CSS或者style样式设置的，而是Canvas绘制的整个图片
    - 该缺口没有具体的属性值，就需要截取缺口出现前后的两张图片
    - 通过对比图片找出缺口的四个角的坐标位置，然后计算出来移动的距离
    - 可以移动的小图是有属性的，只是缺口图是绘制的
- 参考004/005案例

## 7.5 点选文字验证码
- 点选文字一般都是生僻字繁体字
- OCR识别率都较低
- 需要使用深度学习模块，大量学习后识别

## 7.6 鼠标轨迹检测
- 网页可以纪录鼠标轨迹，鼠标每移动一个像素就会纪录一次坐标值
- selenium模拟鼠标移动，轨需要使用操作大量移动，鼠标移动次数要超过两点之间最短距离的鼠标纪录次数


# 8 综合知识
## 8.1 编码与加密
### 8.1.1 ASCII编码
- ASCII是基于拉丁字母表的一套计算机编码系统，用于显示现代英语和其它西欧语言
- 实际是约定了字符和二进制的映射关系，可以看做二进制与拉丁字符的映射表
- ASCII编码中：拉丁字符和常用符号可以映射为二进制，十进制和十六进制
- 参考图片001/002

## 8.1.2 Base64编码
- 编码过程：
    - 字符串--->ASCII码--->8位二进制--->6位二进制(000000补全)--->十进制(65补全)--->十进制数在Base64编码表中对应的字符(=补全)
- 一般特殊字符串末尾有=或者==就考虑可能是Base64编码以后的字符
- Base64解码模块，解码就是编码的逆向过程即可
- 参考案例003

- 案例004是base64编码实现的具体步骤
    - base64从8位二进制，是取的6位数组成6位二进制
    - 此处我们可以取5位二进制或者4位二进制，就可以形成新的编码规则了
    
## 8.1.3 MD5消息摘要算法
- MD5消息摘要算法一种广泛采用的散列函数，可以将任何长度的消息转换为128位的消息摘要（大小为16字节）
- MD5是不可逆的，字符串可以转换为MD5值，但是MD5值不能转换成原字符串 
- MD5只能进行正向运算，不能进行逆向运算，常用于密码存储、文件校验场景
- MD5特性：不可逆、压缩、输出结果不可读性，即使密码泄露，只是泄露MD5值，还是无法得到原始密码
- 网站保存的密码只是用户密码的MD5值，用户输入密码时，将用户密码的MD5值和服务器的MD5值进行比较验证

- MD5不可逆的原因是其是一种散列函数，使用的是hash算法，在计算过程中原文的部分信息是丢失了的
    - 什么是可逆的，什么是不可逆的？ 
    - 100（/2）=50 这个过程是可逆的  50（*2）=100
    - 这个*2就是/2的逆向操作  
    - 100(%49)=2
    - 这个%49就是不可逆的，因为51，100，149，198对49取余数都得2。
- 在操作过程中某些信息丢失了，MD5中就有取余操作，还有一些其它操作都会丢失信息，因此没有办法逆向操作来还原。
    - 在安全领域，一般来说可逆的都是加密（逆操作是解密），而MD5，不是加密，只是摘要算法。
    - 摘要可以用以验证内容是否被篡改（这需要通过不同信道传递内容和摘要），从而保证完整性，而加密/解密是用来保证私秘性。
    - 不可逆带来的好处是，在网站的用户口令可以以MD5摘要的方式存储，然后用户登录时输入的口令进行摘要后跟存储的摘要进行比对就可以进行身份认证，
    - 而由于MD5的不可逆，所以即使被拖库，也不会泄漏用户口令。
    
- 消息摘要算法都是不可逆的，同样的消息摘要算法还有SHA1 SHA256

### 8.1.4 对称加密与AES
- 加密和解密时候使用同一个密钥的加密方式叫做对称加密。使用不同的密钥叫做非对称加密。
- 对称加密速度更快，大量数据加密一般都使用对称加密。
- AES（Advanced encryption standard）高级加密标准，最常用的对称加密算法。
    - AES加密过程中的操作都是可逆的
    - 关键是要知道密钥，加密和解密过程都需要使用密钥
    
    
- Python中的AES库pycrypto
    - 安装库：pip install pycrypto 
    - 直接安装报错，下载whl文件到本地后安装
- AES加密需要传入三个参数：密钥，加密模式，IV(初始化向量)
    - 密钥：
        - AES key must be either 16, 24, or 32 bytes long
        - AES密钥就是数字和字母的一个字符串，可以自己定义，长度是固定的16 24 32位
    - 加密模式：
        - ECB：Electronic Code Book（电子码本模式） 
        - CBC：Cipher Block Chaining（密码块链模式） 
        - CTR：Counter（计数器模式）
    - 初始化向量
        - 初始化向量（英语：initialization vector，缩写为IV），或译初向量，
        - 又称初始变量（starting variable，缩写为SV），是一个固定长度的输入值。
        - 一般的使用上会要求它是随机数或拟随机数（pseudorandom）。
        - 使用随机数产生的初始化向量才能达到语义安全（散列函数与消息验证码也有相同要求），
        - 并让攻击者难以对同一把密钥的密文进行破解。
        - 在区块加密中，使用了初始化向量的加密模式被称为区块加密模式。
        
### 8.1.5 非对称加密和RSA
- 加密和解密过程使用的密钥是不相同的，所以叫非对称加密
    - 加密和解密分别使用公钥和私钥
    - python中还是使用pycrypto进行RSA加密解密
    - 注意：006案例会报错ImportError: No module named 'winrandom'
    - 解决方法：
        - 修改python安装目录下的 lib/Crypto/Random/OSRNG/nt.py 文件中以下代码：
        - import winrandom
        - 修改为：
        - from Crypto.Random.OSRNG import winrandom
        
## 8.2 JavaScript代码混淆
- 目的：代码混淆后，降低代码易读性，混淆后的代码无法都是一些不可读的代码或者符号
    - 防止有心人调试网页代码，混淆后增加理解和调试的难度
    - 混淆后的代码在浏览器的console调试窗口运行，因为本质还是JavaScript代码
- 常用混淆方法：正则替换、代码编码、代码复杂化
- 混淆过程不是加密，混淆代码可以还原，只是不同混淆手段还原需要的时间不同
- 混淆原理：
    - 抽象语法树，JS编译器的目的是把JS代码编译为机器码，
    - 混淆器修改的就是编译过程中的语法树
    - 经过混淆器修改后本质还是JS代码，只是我们可读的代码失去了可读性

## 8.3 鼠标禁止事件
- HTML DOM对象允许JavaScript在HTML文档中注册不同的事件，当事件触发时就会触发对应的JavaScript代码
- 鼠标事件：
    - onclick       鼠标点击
    - oncontextmenu 鼠标右键菜单
    - onmousedown   鼠标按下
    - onmousemove   鼠标移动
    - oncopy        复制内容
    - 使用都是document.onclick
- 键盘事件：
    - onkeydown     键盘按下
- 具体使用参考008/009/010案例
- 参考011-013图片

